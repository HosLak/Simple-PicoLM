import torch
from torch.utils.data import DataLoader
import time
import warnings
warnings.filterwarnings('ignore')

from .config import ModelConfig
from .data_utils import set_seed, load_and_cache_data, TextTokenDataset
from .training_utils import train_model, save_model

def main():
    # Check system
    print(f"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}")
    if torch.cuda.is_available():
        print(f"GPU: {torch.cuda.get_device_name()}")
        print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
    # Set seed
    set_seed(1337)

    # Create config
    config = ModelConfig()
    print(f"\nModel Configuration:")
    print(f"   Architecture: {config.d_model}d, {config.n_layers}L, {config.n_heads}H, {config.d_ff}ff")
    print(f"   Training: {config.max_steps} steps, batch size {config.batch_size}")
    print(f"   Data: {config.max_tokens:,} tokens, seq_len {config.max_seq_len}")

    # Load data
    texts, tokenizer, tokens = load_and_cache_data(config)
    dataset = TextTokenDataset(tokens, config.max_seq_len, config.stride)
    
    # Train/val split
    val_size = len(dataset) // 10
    train_size = len(dataset) - val_size

    train_dataset, val_dataset = torch.utils.data.random_split(
        dataset, [train_size, val_size], generator=torch.Generator().manual_seed(1337)
    )

    # train_dataset = torch.utils.data.Subset(
    # dataset,
    # range(train_size),
    # )
    # val_dataset = torch.utils.data.Subset(
    #     dataset,
    #     range(val_size),
    # )
    
    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=config.batch_size, shuffle=False)

    print(f"Dataset: {len(train_dataset)} train, {len(val_dataset)} val samples")

    # Train model
    start_time = time.time()
    model, final_metrics = train_model(config, train_loader, val_loader)
    total_time = time.time() - start_time
    
    print(f"\n TRAINING COMPLETED!")
    save_model(model, "PicoLMModel.pt")
    print(f" Total time: {total_time/60:.1f} minutes")
    print(f" Final Results:")
    print(f"   Validation Loss: {final_metrics['val_loss']:.4f}")
    print(f"   Validation Accuracy: {final_metrics['val_accuracy']:.4f}")
    print(f"   Validation Perplexity: {final_metrics['val_perplexity']:.2f}")
